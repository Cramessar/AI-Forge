# ğŸ§  AI Forge

**AI Forge** is a locally-powered desktop AI app I built to make using models like `mistral`, `llama2`, or `codellama` easier, faster, and more funâ€”without relying on API keys or an internet connection. If you've ever thought "I just want to run a model without jumping through five cloud hoops," welcome. Youâ€™re among friends now.

This app uses [Ollama](https://ollama.com) under the hood and is fully local-first. Itâ€™s meant to be simple for general users, powerful for devs, and welcoming for anyone who wants to explore AIâ€”without a monthly bill.

---

## ğŸš€ Why I Built This

AI is powerful. But for a lot of people, itâ€™s also confusing, expensive, or locked behind services they donâ€™t control. I wanted to change that.

So I built **AI Forge** to:
- Make **local AI** more accessible for everyone
- Let folks generate, experiment, and create **without needing the cloud**
- Support amazing projects like **Ollama**, which make running models easy
- Build something the community can shape and grow together

This is a project I plan to keep working on. But honestly? The best version of AI Forge will come from more than just me. Your perspective, ideas, and skills can take this to places I havenâ€™t imagined.

Together, we can make AI tools that **belong to the people**, not the platforms. Let's bring AI to the massesâ€”no gatekeepers, no paywalls, no problem.

---

## ğŸ§© Features

- ğŸ§  Model switching via Ollama (`mistral`, `codellama`, etc.)
- ğŸ”„ Real-time streaming output (with style)
- ğŸ’¡ Syntax-highlighted code blocks (yes, finally readable code!)
- ğŸ› ï¸ CPU / GPU backend benchmarking + tuning
- ğŸ“¥ PDF, Markdown, TXT file importing
- ğŸ’¾ Automatic local history caching (via SQLite)
- ğŸ“œ Manual session save/load
- ğŸ¨ Dark-mode friendly with fully themed UI

Basically, itâ€™s like ChatGPT met a local dev tool, drank some Red Bull, and decided to move off-grid.

---

## ğŸ“¦ Installation

```bash
# Clone the repo
git clone https://github.com/cramessar/ai-forge.git
cd ai-forge

# Install dependencies
pip install -r requirements.txt

# Make sure Ollama is installed
# Then download a model like mistral
ollama run mistral

# Launch the app
python app.py
```

Note: Runs best on Python 3.10+ (and yes, I tested this more times than Iâ€™ve tested my own patience).

---

## ğŸ‘¤ Who This Is For

### ğŸ“ General Users
- Students, bloggers, storytellers, curious humans
- Want to write, summarize, or brainstorm without the tech overhead

### ğŸ§‘â€ğŸ’» Advanced Users
- Developers, researchers, tinkerers
- Want full control over models, backends, and configurations

---

## ğŸ›  How to Use It

1. **Pick a Model**
   - Use the ğŸ§  dropdown
   - I recommend `mistral` for general tasks or `codellama` for dev work

2. **Type Your Prompt**
   - Example:  
     - "Write a pitch for a cyberpunk bagel startup"  
     - "Explain quantum entanglement like Iâ€™m five"

3. **Click Generate**
   - Sit back and watch the AI do its thing

4. **Optional Tweaks**
   - Temperature = creativity
   - Max Tokens = response length

5. **Import Files**
   - PDFs, markdown, and text files are fair game

6. **Save or Load**
   - Save a session as `.json`  
   - Reopen later for ongoing projects

7. **Forget to Save?**
   - Donâ€™t worry, I added SQLite caching so your stuff sticks around  
   - (Unless you delete the file. Thenâ€¦ well, donâ€™t do that.)

---

## ğŸ§ª Performance Tweaks

- Open ğŸ› ï¸ **Settings**
- Choose **CPU**, **GPU**, or **Auto**
- Run **Benchmark** to test which is faster
- GPU's faster? Great. CPUâ€™s faster? Still great.  
- Auto just picks the winner for you, like a non-judgmental referee.

---

## ğŸ—ƒ Local History (SQLite FTW)

All prompts + responses are stored automatically in `history.db`:

- Appears in the sidebar
- Saved silently in the background
- Doesnâ€™t require saving a session manually

Think of it as a memory that doesnâ€™t forgetâ€”even when you do.

---

## âœï¸ Developer Notes

- All config lives in `config.json`
- Backend tuning and session persistence is built-in
- Database logic lives in `db.py` (SQLite by default, swappable)
- Models are served using **Ollama**â€”so get cozy with `ollama run` and `ollama list`

Pro tip: yes, you can theme it, mod it, or plug in your own models.

---

## ğŸŒ Community Call

AI Forge is open source, and Iâ€™d love your help.

- Got ideas for features?
- Want to add plugin support?
- Got a custom use case?

Whether you're writing code, spotting bugs, designing UI, or suggesting ideasâ€”youâ€™re welcome here.

Letâ€™s build something that helps people **create freely, learn deeply, and explore widely**â€”without being held hostage by cloud pricing.

---

## â¤ï¸ Thanks & Acknowledgments

- [Ollama](https://ollama.com) â€” Seriously, go support them. Theyâ€™re doing incredible work.
- Pygments â€” For making code look less like chicken scratch.
- Markdown2 â€” For doing what Markdown does best: just working.

---

## ğŸ“š Roadmap / Coming Soon

- Custom model profiles
- Queryable local history
- Plugin system (Notion? VS Code? Terminal dragons?)
- Community prompt sharing
- Batch generation

---

### ğŸ§™ Final Thoughts

> â€œNot all who wander are lost... but some are just looking for a local AI tool that respects their GPU.â€

Thanks for checking out AI Forge.  
Now go forth and generate something epic.

â€” _Chris_
